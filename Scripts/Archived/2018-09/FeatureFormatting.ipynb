{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script formats articles by features for linear regression (first attempt).  \n",
    "It takes in a list of features and a set of articles and creates a frequency matrix (sparse)  \n",
    "While this isn't the cleverest method, it provides a usable input for setting up our initial linear regression code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from whoosh import index, writing\n",
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
    "from whoosh.analysis import *\n",
    "txtCleaner = RegexTokenizer() | LowercaseFilter() | StopFilter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the list of feature words\n",
    "## current list based on unigrams extracted from rbc's retail articles\n",
    "with open(\"rbc_feature_set-retail.csv \",\"r\",encoding=\"utf8\") as wordFile:\n",
    "    wordList = wordFile.read()\n",
    "    wordList = wordList.splitlines()\n",
    "    wordList = [word.strip(\"\"\" ,.*()[]!@#$%^&*{}?_'`\"-\"\"\") for word in wordList]\n",
    "#print(wordList)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"retailarticles.csv \",\"r\") as dataFile:\n",
    "    dataText = dataFile.read()\n",
    "    dataText = dataText.splitlines()\n",
    "    size = len(dataText)\n",
    "    \n",
    "    df = pd.DataFrame(np.zeros([size,100]),columns=wordList)\n",
    "    i = 0\n",
    "    for line in dataText:\n",
    "        body = line.split(\",\")\n",
    "        fts = [token.text for token in txtCleaner(body[5])]\n",
    "        wordsCounter = Counter(fts)\n",
    "        for word in wordList:\n",
    "            if word in wordsCounter:\n",
    "                df[word].iloc[i] = wordsCounter[word]\n",
    "        #list(filter(lambda word: word in wordsCounter, wordList))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df, path_or_buf='formatted-features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
