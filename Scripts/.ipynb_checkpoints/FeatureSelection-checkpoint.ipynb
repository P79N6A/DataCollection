{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features (stops words removed) by tokenizing corpus - no stemming in baseline\n",
    "#Binary encoding\n",
    "#Assign target group \n",
    "#Use mutual information to get final feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData():\n",
    "    #Import Labelled Data\n",
    "    DATA_DIR = \"Data\"\n",
    "    thispath = Path().absolute()\n",
    "    RET_ARTICLES = os.path.join(DATA_DIR, \"retailarticles YTD (new)_merged.csv\")\n",
    "\n",
    "    df = pd.read_csv(RET_ARTICLES, encoding= \"ISO-8859-1\")\n",
    "\n",
    "    try:\n",
    "        df.head()\n",
    "    except:\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignStopWords(): \n",
    "    #Stop_words list Options\n",
    "    stop_words = {'audio','i', 'me', 'us', 'my','myself','we','our','ours', 'ourselves','you', 'your', 'yours', 'yourself', 'yourselves','he',\t 'him',\t 'his',\t 'himself',\t 'she',\t 'her',\t 'hers',\t 'herself',\t 'it',\t 'its',\t 'itself',\t 'they','them','their', 'theirs', 'themselves', 'what', 'which', 'who','whom', 'this', 'that', 'these', 'those',\t 'am',\t 'is',\t 'are',\t 'was',\t 'were',\t 'be',\t 'been',\t 'being',\t 'have',\t 'has',\t 'had',\t 'having',\t 'do',\t 'does',\t 'did',\t 'doing',\t 'a',\t 'an',\t 'the',\t 'and',\t 'but',\t 'if',\t 'or',\t 'because',\t 'as',\t 'until',\t 'while',\t 'of',\t 'at',\t 'by',\t 'for',\t 'with',\t 'about',\t 'into',\t 'through',\t 'during',\t 'before',\t 'after',\t 'to',\t 'from','up','down','in','out','on','off','over',\t 'under',\t 'again',\t 'further',\t 'then',\t 'once',\t 'here',\t 'there',\t 'when',\t 'where',\t 'why',\t 'how',\t 'all',\t 'any',\t 'both',\t 'each',\t 'few',\t 'more',\t 'most',\t 'other',\t 'some',\t 'such',\t 'no',\t 'nor',\t 'not',\t 'only','own','same', 'so','than', 'too','very','s','t','can', 'will', 'just','don','should', 'now'}\n",
    "\n",
    "    #from nltk.corpus import stopwords\n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "    #print(stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_count_words(df, stop_words):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_counter = Counter()\n",
    "    for row in df.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, 'content'))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            #keep lowercased words that are not stop words as features\n",
    "            file_wordsNS = [word.lower() for word in file_words if not word.lower() in stop_words]\n",
    "            word_counter.update(file_wordsNS)\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt = corpus_count_words(df1,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary encoding for features, also appends retail target group\n",
    "def binary_encode_features(newsarticles, top_words):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for row in newsarticles.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, 'content'))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            df_rows.append([1 if word.lower() in file_words else 0 for word in top_words])      \n",
    "    X = pd.DataFrame(df_rows, columns = top_words)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInformation(B_Encoding, y, top_words): \n",
    "    #Estimate mutual information for a discrete target variable.\n",
    "    #Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables.\n",
    "    #It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "    featureVals= mutual_info_classif(B_Encoding, y, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    \n",
    "    np.asarray(featureVals)\n",
    "\n",
    "    Temp= pd.DataFrame(featureVals, columns = ['MI_Values'])\n",
    " \n",
    "    Final = Temp.assign(target_group = top_words)\n",
    "    \n",
    "    Highest_Features = Final.nlargest(250, 'MI_Values')\n",
    "    \n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(featureVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(**kwargs):\n",
    "    df = importData()\n",
    "    stop_words = assignStopWords()\n",
    "    \n",
    "    #Select subset of orig data\n",
    "    df1 = df[['content','Retail Relevance']]    \n",
    "    news_cnt = corpus_count_words(df1, stop_words)\n",
    "    \n",
    "    num_features = 1000\n",
    "    top_words = [word for (word, freq) in news_cnt.most_common(num_features)]\n",
    "    B_Encoding = binary_encode_features(df1, top_words)\n",
    "    y = df['Retail Relevance']\n",
    "    B_Encoding.assign(target_group=y)\n",
    "      \n",
    "    \n",
    "    Highest_Features = mutualInformation(B_Encoding, y, top_words)\n",
    "    Highest_Features = pd.DataFrame(Highest_Features)\n",
    "    \n",
    "    # Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = 'retailFeatureSet.csv'\n",
    "        thispath = Path().absolute()\n",
    "        OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "        \n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        pd.DataFrame.to_csv(Highest_Features, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(Highest_Features, path_or_buf=file_name)\n",
    "    \n",
    "    print(Highest_Features)\n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    HF = selectFeatures(csv = True)\n",
    "    return HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MI_Values target_group\n",
      "27    0.284536            0\n",
      "136   0.118413            1\n",
      "542   0.056787       stores\n",
      "719   0.055051    retailers\n",
      "667   0.033363       brands\n",
      "26    0.031589      company\n",
      "945   0.028351        store\n",
      "122   0.027331        sales\n",
      "806   0.026988        brand\n",
      "8     0.025493          gap\n",
      "485   0.020142       retail\n",
      "52    0.019644     economic\n",
      "398   0.019521     companys\n",
      "368   0.018498       online\n",
      "36    0.018119   government\n",
      "249   0.018093       shares\n",
      "512   0.015814       google\n",
      "35    0.015765        since\n",
      "186   0.013918      however\n",
      "58    0.013111      economy\n",
      "618   0.012592    employers\n",
      "319   0.012556     reported\n",
      "545   0.012548        asked\n",
      "67    0.012321      markets\n",
      "291   0.012195          law\n",
      "539   0.012077           gt\n",
      "564   0.011662      instead\n",
      "281   0.011467      finance\n",
      "860   0.011447      largely\n",
      "685   0.011418    committee\n",
      "..         ...          ...\n",
      "193   0.004121         five\n",
      "99    0.004113          end\n",
      "44    0.004095        still\n",
      "146   0.004092    executive\n",
      "555   0.004079        shows\n",
      "773   0.004030      leading\n",
      "738   0.003996     chairman\n",
      "908   0.003992    challenge\n",
      "9     0.003987          per\n",
      "586   0.003955         asia\n",
      "852   0.003948      towards\n",
      "17    0.003942    companies\n",
      "993   0.003933    forecasts\n",
      "764   0.003933     students\n",
      "114   0.003933     interest\n",
      "227   0.003928   management\n",
      "566   0.003908        areas\n",
      "405   0.003902         done\n",
      "842   0.003895      twitter\n",
      "323   0.003893         2015\n",
      "818   0.003885      october\n",
      "708   0.003877  competition\n",
      "151   0.003842    political\n",
      "298   0.003840        major\n",
      "384   0.003837       theyre\n",
      "895   0.003827       agency\n",
      "789   0.003817       review\n",
      "490   0.003807           ms\n",
      "510   0.003756    following\n",
      "671   0.003749      measure\n",
      "\n",
      "[250 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "Highest_Features = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      target_group\n",
      "27               0\n",
      "136              1\n",
      "719      retailers\n",
      "542         stores\n",
      "667         brands\n",
      "122          sales\n",
      "8              gap\n",
      "485         retail\n",
      "945          store\n",
      "806          brand\n",
      "36      government\n",
      "26         company\n",
      "398       companys\n",
      "368         online\n",
      "176  international\n",
      "319       reported\n",
      "21             may\n",
      "544        results\n",
      "52        economic\n",
      "227     management\n",
      "654      questions\n",
      "539             gt\n",
      "121         gender\n",
      "71       countries\n",
      "256         chinas\n",
      "716       starting\n",
      "606         helped\n",
      "68          policy\n",
      "415      customers\n",
      "62      investment\n",
      "..             ...\n",
      "753        receive\n",
      "726       progress\n",
      "613    significant\n",
      "171         former\n",
      "327    governments\n",
      "949         summit\n",
      "87         average\n",
      "969       families\n",
      "337           life\n",
      "843   unemployment\n",
      "946           drop\n",
      "394          board\n",
      "514           idea\n",
      "130            yet\n",
      "922        sectors\n",
      "359        looking\n",
      "484        started\n",
      "962           room\n",
      "642       november\n",
      "312           hard\n",
      "37             two\n",
      "66            rate\n",
      "940         larger\n",
      "418          korea\n",
      "448           mean\n",
      "373            amp\n",
      "369          issue\n",
      "231           real\n",
      "234        tariffs\n",
      "561       building\n",
      "\n",
      "[250 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(Highest_Features['target_group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = pd.DataFrame(Highest_Features['target_group'])\n",
    "    \n",
    "# Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "\n",
    "\n",
    "# File path for this file\n",
    "file_name = 'retailFeatureSet.csv'\n",
    "thispath = Path().absolute()\n",
    "OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "\n",
    "# if the following line throws an error, use the line after to save in same folder\n",
    "pd.DataFrame.to_csv(featureSet, path_or_buf=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
