{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features (stops words removed) by tokenizing corpus - no stemming in baseline\n",
    "#Binary encoding\n",
    "#Assign target group \n",
    "#Use mutual information to get final feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData():\n",
    "    #Import Labelled Data\n",
    "    DATA_DIR = \"Data\"\n",
    "    thispath = Path().absolute()\n",
    "    #dtype = {\"index\": str, \"title\": str, \"description\": str, \"url\": str, \"date\": str, \"Retail Relevance\": str, \"Economy Relevant\": str, \"Market moving\": str}\n",
    "    RET_ARTICLES = os.path.join(DATA_DIR, \"retailarticles-18-11-06.xlsx\")\n",
    "\n",
    "    \n",
    "    df = pd.read_excel(RET_ARTICLES)\n",
    "\n",
    "    try:\n",
    "        df.head()\n",
    "    except:\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignStopWords(): \n",
    "    #Stop_words list Options\n",
    "    stop_words = {'audio','i', 'me', 'us', 'my','myself','we','our','ours', 'ourselves','you', 'your', 'yours', 'yourself', 'yourselves','he',\t 'him',\t 'his',\t 'himself',\t 'she',\t 'her',\t 'hers',\t 'herself',\t 'it',\t 'its',\t 'itself',\t 'they','them','their', 'theirs', 'themselves', 'what', 'which', 'who','whom', 'this', 'that', 'these', 'those',\t 'am',\t 'is',\t 'are',\t 'was',\t 'were',\t 'be',\t 'been',\t 'being',\t 'have',\t 'has',\t 'had',\t 'having',\t 'do',\t 'does',\t 'did',\t 'doing',\t 'a',\t 'an',\t 'the',\t 'and',\t 'but',\t 'if',\t 'or',\t 'because',\t 'as',\t 'until',\t 'while',\t 'of',\t 'at',\t 'by',\t 'for',\t 'with',\t 'about',\t 'into',\t 'through',\t 'during',\t 'before',\t 'after',\t 'to',\t 'from','up','down','in','out','on','off','over',\t 'under',\t 'again',\t 'further',\t 'then',\t 'once',\t 'here',\t 'there',\t 'when',\t 'where',\t 'why',\t 'how',\t 'all',\t 'any',\t 'both',\t 'each',\t 'few',\t 'more',\t 'most',\t 'other',\t 'some',\t 'such',\t 'no',\t 'nor',\t 'not',\t 'only','own','same', 'so','than', 'too','very','s','t','can', 'will', 'just','don','should', 'now'}\n",
    "\n",
    "    #from nltk.corpus import stopwords\n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "    #print(stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_count_words(df, stop_words):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_counter = Counter()\n",
    "    for row in df.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, 'content'))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            #keep lowercased words that are not stop words as features\n",
    "            file_wordsNS = [word.lower() for word in file_words if not word.lower() in stop_words]\n",
    "            word_counter.update(file_wordsNS)\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt = corpus_count_words(df1,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary encoding for features, also appends retail target group\n",
    "def binary_encode_features(newsarticles, top_words):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for row in newsarticles.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, 'content'))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            df_rows.append([1 if word.lower() in file_words else 0 for word in top_words])      \n",
    "    X = pd.DataFrame(df_rows, columns = top_words)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInformation(B_Encoding, y, top_words): \n",
    "    #Estimate mutual information for a discrete target variable.\n",
    "    #Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables.\n",
    "    #It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "    featureVals= mutual_info_classif(B_Encoding, y, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    \n",
    "    np.asarray(featureVals)\n",
    "\n",
    "    Temp= pd.DataFrame(featureVals, columns = ['MI_Values'])\n",
    " \n",
    "    Final = Temp.assign(target_group = top_words)\n",
    "    \n",
    "    Highest_Features = Final.nlargest(250, 'MI_Values')\n",
    "    \n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(featureVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(**kwargs):\n",
    "    df = importData()\n",
    "    stop_words = assignStopWords()\n",
    "    \n",
    "    #Select subset of orig data\n",
    "    df1 = df[['content','Retail Relevance']]    \n",
    "    news_cnt = corpus_count_words(df1, stop_words)\n",
    "    \n",
    "    num_features = 1000\n",
    "    top_words = [word for (word, freq) in news_cnt.most_common(num_features)]\n",
    "    B_Encoding = binary_encode_features(df1, top_words)\n",
    "    y = df['Retail Relevance']\n",
    "    B_Encoding.assign(target_group=y)\n",
    "      \n",
    "    \n",
    "    Highest_Features = mutualInformation(B_Encoding, y, top_words)\n",
    "    Highest_Features = pd.DataFrame(Highest_Features)\n",
    "    \n",
    "    # Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = 'retailFeatureSet.csv'\n",
    "        thispath = Path().absolute()\n",
    "        OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "        \n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        pd.DataFrame.to_csv(Highest_Features, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(Highest_Features, path_or_buf=file_name)\n",
    "    \n",
    "    print(Highest_Features)\n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    HF = selectFeatures(csv = True)\n",
    "    return HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MI_Values target_group\n",
      "2    1.191895e-03      content\n",
      "5    8.939213e-04            1\n",
      "3    5.959476e-04      company\n",
      "45   5.959476e-04     commerce\n",
      "425  5.959476e-04   government\n",
      "4    2.979738e-04         year\n",
      "11   2.979738e-04         also\n",
      "35   2.979738e-04        years\n",
      "36   2.979738e-04        group\n",
      "37   2.979738e-04     retailer\n",
      "73   2.979738e-04        still\n",
      "83   2.979738e-04        based\n",
      "125  2.979738e-04         told\n",
      "137  2.979738e-04          pay\n",
      "143  2.979738e-04     reported\n",
      "152  2.979738e-04         part\n",
      "180  2.979738e-04         firm\n",
      "241  2.979738e-04     recently\n",
      "430  2.979738e-04         four\n",
      "438  2.979738e-04    following\n",
      "520  2.979738e-04         jobs\n",
      "0    2.220446e-16       amazon\n",
      "1    2.220446e-16         said\n",
      "6    2.220446e-16      walmart\n",
      "7    2.220446e-16      percent\n",
      "8    2.220446e-16          new\n",
      "9    2.220446e-16       stores\n",
      "10   2.220446e-16        sales\n",
      "12   2.220446e-16        index\n",
      "13   2.220446e-16       online\n",
      "..            ...          ...\n",
      "215  2.220446e-16        cloud\n",
      "216  2.220446e-16        apple\n",
      "217  2.220446e-16         news\n",
      "218  2.220446e-16     increase\n",
      "219  2.220446e-16      against\n",
      "220  2.220446e-16      capital\n",
      "221  2.220446e-16      growing\n",
      "222  2.220446e-16       likely\n",
      "223  2.220446e-16         2016\n",
      "224  2.220446e-16       called\n",
      "225  2.220446e-16           15\n",
      "226  2.220446e-16   businesses\n",
      "227  2.220446e-16    locations\n",
      "228  2.220446e-16       friday\n",
      "229  2.220446e-16   investment\n",
      "230  2.220446e-16     research\n",
      "231  2.220446e-16         cost\n",
      "232  2.220446e-16        space\n",
      "233  2.220446e-16        offer\n",
      "234  2.220446e-16      results\n",
      "235  2.220446e-16          far\n",
      "236  2.220446e-16    statement\n",
      "237  2.220446e-16        among\n",
      "238  2.220446e-16       become\n",
      "239  2.220446e-16            0\n",
      "240  2.220446e-16        lower\n",
      "242  2.220446e-16     spending\n",
      "243  2.220446e-16         york\n",
      "244  2.220446e-16         come\n",
      "245  2.220446e-16       season\n",
      "\n",
      "[250 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "Highest_Features = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd.DataFrame(Highest_Features['target_group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = pd.DataFrame(Highest_Features['target_group'])\n",
    "    \n",
    "# Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "\n",
    "\n",
    "# File path for this file\n",
    "file_name = 'retailFeatureSet.csv'\n",
    "thispath = Path().absolute()\n",
    "OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "\n",
    "# if the following line throws an error, use the line after to save in same folder\n",
    "pd.DataFrame.to_csv(featureSet, path_or_buf=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
