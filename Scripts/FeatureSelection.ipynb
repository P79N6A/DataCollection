{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features (stops words removed) by tokenizing corpus - no stemming in baseline\n",
    "#Binary encoding\n",
    "#Assign target group \n",
    "#Use mutual information to get final feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData():\n",
    "    #Import Labelled Data\n",
    "    DATA_DIR = \"Data\"\n",
    "    thispath = Path().absolute()\n",
    "    RET_ARTICLES = os.path.join(DATA_DIR, \"retailarticles YTD (new)_merged.csv\")\n",
    "\n",
    "    df = pd.read_csv(RET_ARTICLES, encoding= \"ISO-8859-1\")\n",
    "\n",
    "    try:\n",
    "        df.head()\n",
    "    except:\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignStopWords(): \n",
    "    #Stop_words list Options\n",
    "    stop_words = {'audio','i', 'me', 'us', 'my','myself','we','our','ours', 'ourselves','you', 'your', 'yours', 'yourself', 'yourselves','he',\t 'him',\t 'his',\t 'himself',\t 'she',\t 'her',\t 'hers',\t 'herself',\t 'it',\t 'its',\t 'itself',\t 'they','them','their', 'theirs', 'themselves', 'what', 'which', 'who','whom', 'this', 'that', 'these', 'those',\t 'am',\t 'is',\t 'are',\t 'was',\t 'were',\t 'be',\t 'been',\t 'being',\t 'have',\t 'has',\t 'had',\t 'having',\t 'do',\t 'does',\t 'did',\t 'doing',\t 'a',\t 'an',\t 'the',\t 'and',\t 'but',\t 'if',\t 'or',\t 'because',\t 'as',\t 'until',\t 'while',\t 'of',\t 'at',\t 'by',\t 'for',\t 'with',\t 'about',\t 'into',\t 'through',\t 'during',\t 'before',\t 'after',\t 'to',\t 'from','up','down','in','out','on','off','over',\t 'under',\t 'again',\t 'further',\t 'then',\t 'once',\t 'here',\t 'there',\t 'when',\t 'where',\t 'why',\t 'how',\t 'all',\t 'any',\t 'both',\t 'each',\t 'few',\t 'more',\t 'most',\t 'other',\t 'some',\t 'such',\t 'no',\t 'nor',\t 'not',\t 'only','own','same', 'so','than', 'too','very','s','t','can', 'will', 'just','don','should', 'now'}\n",
    "\n",
    "    #from nltk.corpus import stopwords\n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "    #print(stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_count_words(df, stop_words):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_counter = Counter()\n",
    "    for row in df.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, 'content'))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            #keep lowercased words that are not stop words as features\n",
    "            file_wordsNS = [word.lower() for word in file_words if not word.lower() in stop_words]\n",
    "            word_counter.update(file_wordsNS)\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt = corpus_count_words(df1,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary encoding for features, also appends retail target group\n",
    "def binary_encode_features(newsarticles, top_words):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for row in newsarticles.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, 'content'))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            df_rows.append([1 if word.lower() in file_words else 0 for word in top_words])      \n",
    "    X = pd.DataFrame(df_rows, columns = top_words)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInformation(B_Encoding, y, top_words): \n",
    "    #Estimate mutual information for a discrete target variable.\n",
    "    #Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables.\n",
    "    #It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "    featureVals= mutual_info_classif(B_Encoding, y, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    \n",
    "    np.asarray(featureVals)\n",
    "\n",
    "    Temp= pd.DataFrame(featureVals, columns = ['MI_Values'])\n",
    " \n",
    "    Final = Temp.assign(target_group = top_words)\n",
    "    \n",
    "    Highest_Features = Final.nlargest(250, 'MI_Values')\n",
    "    \n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(featureVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(**kwargs):\n",
    "    df = importData()\n",
    "    stop_words = assignStopWords()\n",
    "    \n",
    "    #Select subset of orig data\n",
    "    df1 = df[['content','Retail Relevance']]    \n",
    "    news_cnt = corpus_count_words(df1, stop_words)\n",
    "    \n",
    "    num_features = 1000\n",
    "    top_words = [word for (word, freq) in news_cnt.most_common(num_features)]\n",
    "    B_Encoding = binary_encode_features(df1, top_words)\n",
    "    y = df['Retail Relevance']\n",
    "    B_Encoding.assign(target_group=y)\n",
    "      \n",
    "    \n",
    "    Highest_Features = MutualInformation(B_Encoding, y, top_words)\n",
    "    Highest_Features = pd.DataFrame(Highest_Features)\n",
    "    \n",
    "    # Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = 'retailFeatureSet.csv'\n",
    "        thispath = Path().absolute()\n",
    "        OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "        \n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        pd.DataFrame.to_csv(Highest_Features, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(Highest_Features, path_or_buf=file_name)\n",
    "    \n",
    "    print(Highest_Features)\n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    HF = selectFeatures(csv = True)\n",
    "    return HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MI_Values   target_group\n",
      "27    0.285954              0\n",
      "136   0.110000              1\n",
      "719   0.060153      retailers\n",
      "542   0.050662         stores\n",
      "667   0.037418         brands\n",
      "122   0.033319          sales\n",
      "8     0.029119            gap\n",
      "485   0.028773         retail\n",
      "945   0.027683          store\n",
      "806   0.024922          brand\n",
      "36    0.024038     government\n",
      "26    0.022374        company\n",
      "398   0.019415       companys\n",
      "368   0.017491         online\n",
      "176   0.014855  international\n",
      "319   0.014033       reported\n",
      "21    0.013260            may\n",
      "544   0.013093        results\n",
      "52    0.013036       economic\n",
      "227   0.012907     management\n",
      "654   0.012730      questions\n",
      "539   0.012297             gt\n",
      "121   0.012297         gender\n",
      "71    0.012225      countries\n",
      "256   0.011971         chinas\n",
      "716   0.011781       starting\n",
      "606   0.011641         helped\n",
      "68    0.011626         policy\n",
      "415   0.011505      customers\n",
      "62    0.011417     investment\n",
      "..         ...            ...\n",
      "753   0.004078        receive\n",
      "726   0.004066       progress\n",
      "613   0.004030    significant\n",
      "171   0.004020         former\n",
      "327   0.003991    governments\n",
      "949   0.003973         summit\n",
      "87    0.003953        average\n",
      "969   0.003930       families\n",
      "337   0.003905           life\n",
      "843   0.003905   unemployment\n",
      "946   0.003881           drop\n",
      "394   0.003868          board\n",
      "514   0.003853           idea\n",
      "130   0.003852            yet\n",
      "922   0.003850        sectors\n",
      "359   0.003844        looking\n",
      "484   0.003842        started\n",
      "962   0.003821           room\n",
      "642   0.003819       november\n",
      "312   0.003817           hard\n",
      "37    0.003803            two\n",
      "66    0.003801           rate\n",
      "940   0.003793         larger\n",
      "418   0.003786          korea\n",
      "448   0.003705           mean\n",
      "373   0.003697            amp\n",
      "369   0.003672          issue\n",
      "231   0.003663           real\n",
      "234   0.003632        tariffs\n",
      "561   0.003620       building\n",
      "\n",
      "[250 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "Highest_Features = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      target_group\n",
      "27               0\n",
      "136              1\n",
      "719      retailers\n",
      "542         stores\n",
      "667         brands\n",
      "122          sales\n",
      "8              gap\n",
      "485         retail\n",
      "945          store\n",
      "806          brand\n",
      "36      government\n",
      "26         company\n",
      "398       companys\n",
      "368         online\n",
      "176  international\n",
      "319       reported\n",
      "21             may\n",
      "544        results\n",
      "52        economic\n",
      "227     management\n",
      "654      questions\n",
      "539             gt\n",
      "121         gender\n",
      "71       countries\n",
      "256         chinas\n",
      "716       starting\n",
      "606         helped\n",
      "68          policy\n",
      "415      customers\n",
      "62      investment\n",
      "..             ...\n",
      "753        receive\n",
      "726       progress\n",
      "613    significant\n",
      "171         former\n",
      "327    governments\n",
      "949         summit\n",
      "87         average\n",
      "969       families\n",
      "337           life\n",
      "843   unemployment\n",
      "946           drop\n",
      "394          board\n",
      "514           idea\n",
      "130            yet\n",
      "922        sectors\n",
      "359        looking\n",
      "484        started\n",
      "962           room\n",
      "642       november\n",
      "312           hard\n",
      "37             two\n",
      "66            rate\n",
      "940         larger\n",
      "418          korea\n",
      "448           mean\n",
      "373            amp\n",
      "369          issue\n",
      "231           real\n",
      "234        tariffs\n",
      "561       building\n",
      "\n",
      "[250 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(Highest_Features['target_group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = pd.DataFrame(Highest_Features['target_group'])\n",
    "    \n",
    "# Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "\n",
    "\n",
    "# File path for this file\n",
    "file_name = 'retailFeatureSet.csv'\n",
    "thispath = Path().absolute()\n",
    "OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "\n",
    "# if the following line throws an error, use the line after to save in same folder\n",
    "pd.DataFrame.to_csv(featureSet, path_or_buf=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
