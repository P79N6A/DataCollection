{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding\n",
    "\n",
    "The following script formats articles by features for linear regression (first attempt).  \n",
    "It takes in a list of features and a set of articles, converts to lowercase and creates an encoded matrix (dense)  \n",
    "While this isn't the cleverest method, it provides a usable input for setting up our initial linear regression code.\n",
    "\n",
    "### Limitations:\n",
    "* Proper Nouns should keep their capitals\n",
    "* Punctuation/Stemming etc not incorporated\n",
    "* Bi-grams not accommodated\n",
    "* Could be converted to space matrix\n",
    "* No log function incorporated at this point\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyscripter\n",
    "\n",
    "#relevant_nbs = ['FeatureSelection.ipynb']\n",
    "#relevant_nbs = pyscripter.nb_to_py(relevant_nbs)\n",
    "#print(\"y print 2x?\")\n",
    "#print(relevant_nbs)\n",
    "#pyscripter.import_scripts(['FeatureSelection.py'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    DATA_DIR = \"Data\"\n",
    "    FEATURES_DIR = os.path.join(DATA_DIR, \"retailFeatureSet-pmi.csv\")\n",
    "    ARTICLES_DIR = os.path.join(DATA_DIR, \"retailarticles-18-11-06.xlsx\")\n",
    "    \n",
    "    fts = pd.read_csv(FEATURES_DIR)\n",
    "    for col in fts.columns:\n",
    "        if not (col.strip() == 'target_group'):\n",
    "            fts = fts.drop([col], axis = 1)\n",
    "    fts.columns = ['index']\n",
    "    fts['index'] = list(map(lambda x: x.strip(), fts['index']))\n",
    "    arts = pd.read_excel(ARTICLES_DIR)\n",
    "    artText = arts.iloc[:,5]\n",
    "    artID = arts.iloc[:,1]   #**\n",
    "    data = {'fts':fts, 'artText': artText, 'artID': artID} #**\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binEncoding(data):\n",
    "    print(\"Binary Encoding\")\n",
    "    fts = data['fts']\n",
    "    artText = data['artText']\n",
    "    \n",
    "    df_rows = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    for art in artText:\n",
    "        if type(art) == str: \n",
    "            body = art.lower()\n",
    "            #body = clean_file_text(body)\n",
    "            art_words = tokenizer.tokenize(body)\n",
    "            df_rows.append([1 if word in art_words else 0 for word in fts['index']])\n",
    "        else:\n",
    "            df_rows.append([0 for word in fts['index']])\n",
    "    X = pd.DataFrame(df_rows, columns = fts['index'].values)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfEncoding(data):\n",
    "    print(\"tf Encoding\")\n",
    "    fts = data['fts']\n",
    "    artText = data['artText']\n",
    "    \n",
    "    tf_rows = []\n",
    "    for art in artText:\n",
    "        if type(art) == str:\n",
    "            body = art.lower()\n",
    "            body = body.split()\n",
    "            wordsCounter = Counter(body)\n",
    "            tf_rows.append([wordsCounter[word] if word in wordsCounter else 0 for word in fts['index']])\n",
    "        else:\n",
    "            tf_rows.append([0 for word in fts['index']])\n",
    "    X = pd.DataFrame(tf_rows, columns = fts['index'].values)  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfEncoding(data):\n",
    "    print(\"tifidf Encoding\")\n",
    "    fts = data['fts']\n",
    "\n",
    "    # Base calculations\n",
    "    binX = binEncoding(data)\n",
    "    tfX = tfEncoding(data)\n",
    "    \n",
    "    # Calculate idf\n",
    "    df_row = [binX[word].sum() for word in fts['index']]\n",
    "    idf = [1/(df+1) for df in df_row]\n",
    "    #transpose list (not the cleverest method)\n",
    "    idf_row = []\n",
    "    idf_row.append(idf)\n",
    "    idf_list = pd.DataFrame(idf_row, columns = fts['index'])\n",
    "    \n",
    "    # Extract term frequencies\n",
    "    tf = tfX.values\n",
    "    # Set up loop to multiply each article (row) by the idf per term (col)\n",
    "    tf_idf = []\n",
    "    r, c = tf.shape\n",
    "    for art in range(0,r):\n",
    "        tf_idf.append(tf[art]*idf)\n",
    "    tf_idf = pd.DataFrame(tf_idf, columns = fts['index'])\n",
    "    X = tf_idf\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(encodeType, **kwargs):\n",
    "    # 0 for Binary Encoding\n",
    "    # 1 for Term Frequency Encoding\n",
    "    # 2 for TF-IDF Encoding\n",
    "    # If you'd like to save as csv, use \"csv = True\"\n",
    "        \n",
    "    # Load up data\n",
    "    data = loadData()\n",
    "    \n",
    "    # Run corresponding encoding type and pass data\n",
    "    options = {0 : binEncoding,\n",
    "                1 : tfEncoding,\n",
    "                2 : tfidfEncoding,}\n",
    "    \n",
    "    X = options[encodeType](data)\n",
    "    \n",
    "    # Save as csv file in CLASSIFICATION data folder =)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = options[encodeType].__name__ + '-PMI.csv'\n",
    "        thispath = Path().absolute()\n",
    "        #OUTPUT_DIR = os.path.join(thispath.parent.parent, \"Classification\", \"Data\", file_name)\n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "        pd.DataFrame.to_csv(X, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(X, path_or_buf=file_name)\n",
    "    \n",
    "    # Return Panda DataFrame\n",
    "    return X\n",
    "    \n",
    "\n",
    "\n",
    "def main(): # Stuff to do when run from the command line    \n",
    "    encoding(0, csv = True)\n",
    "    pass  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Encoding\n"
     ]
    }
   ],
   "source": [
    "#testcell\n",
    "\n",
    "#X = encoding(1, csv=True)\n",
    "#X = encoding(2, csv=True)\n",
    "X = encoding(0, csv=True)\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf Encoding\n"
     ]
    }
   ],
   "source": [
    "data = loadData()\n",
    "X = tfEncoding(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "5          6\n",
      "6          7\n",
      "7          8\n",
      "8          9\n",
      "9         10\n",
      "10        11\n",
      "11        12\n",
      "12        13\n",
      "13        14\n",
      "14        15\n",
      "15        16\n",
      "16        17\n",
      "17        18\n",
      "18        19\n",
      "19        20\n",
      "20        21\n",
      "21        22\n",
      "22        23\n",
      "23        24\n",
      "24        25\n",
      "25        26\n",
      "26        27\n",
      "27        28\n",
      "28        29\n",
      "29        30\n",
      "        ... \n",
      "2391    2392\n",
      "2392    2393\n",
      "2393    2394\n",
      "2394    2395\n",
      "2395    2396\n",
      "2396    2397\n",
      "2397    2398\n",
      "2398    2399\n",
      "2399    2400\n",
      "2400    2401\n",
      "2401    2402\n",
      "2402    2403\n",
      "2403    2404\n",
      "2404    2405\n",
      "2405    2406\n",
      "2406    2407\n",
      "2407    2408\n",
      "2408    2409\n",
      "2409    2410\n",
      "2410    2411\n",
      "2411    2412\n",
      "2412    2413\n",
      "2413    2414\n",
      "2414    2415\n",
      "2415    2416\n",
      "2416    2417\n",
      "2417    2418\n",
      "2418    2419\n",
      "2419    2420\n",
      "2420    2421\n",
      "Name: index, Length: 2421, dtype: int64\n",
      "   target  company  central  retailer  inflation  stores  bank  child  \\\n",
      "0       2        0        0         1          0       0     0      0   \n",
      "1       0        0        0         1          0       3     0      0   \n",
      "2       1        2        0         1          0       1     0      0   \n",
      "3       0        1        0         3          0       1     0      0   \n",
      "4       0        0        0         0          0       0     0      0   \n",
      "\n",
      "   commerce  online     ...      closer  raided  union  backlog  ocado  evans  \\\n",
      "0         0       3     ...           0       0      0        0      0      0   \n",
      "1         0       1     ...           0       0      0        0      0      0   \n",
      "2         0       3     ...           0       0      0        0      0      0   \n",
      "3         0       1     ...           0       0      0        0      0      0   \n",
      "4         0       0     ...           0       0      0        0      0      0   \n",
      "\n",
      "   tire  phone  moves  triggering  \n",
      "0     0      0      0           0  \n",
      "1     0      0      0           0  \n",
      "2     0      0      0           0  \n",
      "3     0      0      0           0  \n",
      "4     0      0      0           0  \n",
      "\n",
      "[5 rows x 10000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data['artID'])\n",
    "X['index'] = data['artID'].values #**\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
