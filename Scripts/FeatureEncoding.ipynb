{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding\n",
    "\n",
    "The following script formats articles by features for linear regression (first attempt).  \n",
    "It takes in a list of features and a set of articles, converts to lowercase and creates an encoded matrix (dense)  \n",
    "While this isn't the cleverest method, it provides a usable input for setting up our initial linear regression code.\n",
    "\n",
    "### Limitations:\n",
    "* Proper Nouns should keep their capitals\n",
    "* Punctuation/Stemming etc not incorporated\n",
    "* Bi-grams not accommodated\n",
    "* Could be converted to sparse matrix\n",
    "* No log function incorporated at this point\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyscripter\n",
    "\n",
    "#relevant_nbs = ['FeatureSelection.ipynb']\n",
    "#relevant_nbs = pyscripter.nb_to_py(relevant_nbs)\n",
    "#print(\"y print 2x?\")\n",
    "#print(relevant_nbs)\n",
    "#pyscripter.import_scripts(['FeatureSelection.py'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    DATA_DIR = \"Data\"\n",
    "    FEATURES_DIR = os.path.join(DATA_DIR, \"retailFeatureSet-MI.csv\")\n",
    "    ARTICLES_DIR = os.path.join(DATA_DIR, \"Labelled Articles.xlsx\")\n",
    "    \n",
    "    fts = pd.read_csv(FEATURES_DIR)\n",
    "    for col in fts.columns:\n",
    "        if not (col.strip() == 'target_group'):\n",
    "            fts = fts.drop([col], axis = 1)\n",
    "    fts.columns = ['index']\n",
    "    fts['index'] = list(map(lambda x: x.strip(), fts['index']))\n",
    "    arts = pd.read_excel(ARTICLES_DIR)\n",
    "    \n",
    "    # Stripping out columns and only passing what we need\n",
    "    artText = arts['content']\n",
    "    data = {'fts':fts, 'artText': artText, 'article_id': arts['article_id'], 'market_moving':arts['market_moving']} #**\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binEncoding(data):\n",
    "    print(\"Binary Encoding\")\n",
    "    fts = data['fts']\n",
    "    artText = data['artText']\n",
    "    \n",
    "    df_rows = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    for art in artText:\n",
    "        if type(art) == str: \n",
    "            body = art.lower()\n",
    "            #body = clean_file_text(body)\n",
    "            art_words = tokenizer.tokenize(body)\n",
    "            df_rows.append([1 if word in art_words else 0 for word in fts['index']])\n",
    "        else:\n",
    "            df_rows.append([0 for word in fts['index']])\n",
    "    X = pd.DataFrame(df_rows, columns = fts['index'].values)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfEncoding(data):\n",
    "    print(\"tf Encoding\")\n",
    "    fts = data['fts']\n",
    "    artText = data['artText']\n",
    "    \n",
    "    tf_rows = []\n",
    "    for art in artText:\n",
    "        if type(art) == str:\n",
    "            body = art.lower()\n",
    "            body = body.split()\n",
    "            wordsCounter = Counter(body)\n",
    "            tf_rows.append([wordsCounter[word] if word in wordsCounter else 0 for word in fts['index']])\n",
    "        else:\n",
    "            tf_rows.append([0 for word in fts['index']])\n",
    "    X = pd.DataFrame(tf_rows, columns = fts['index'].values)  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfEncoding(data):\n",
    "    print(\"tifidf Encoding\")\n",
    "    fts = data['fts']\n",
    "\n",
    "    # Base calculations\n",
    "    binX = binEncoding(data)\n",
    "    tfX = tfEncoding(data)\n",
    "    \n",
    "    # Calculate idf\n",
    "    df_row = [binX[word].sum() for word in fts['index']]\n",
    "    idf = [1/(df+1) for df in df_row]\n",
    "    #transpose list (not the cleverest method)\n",
    "    idf_row = []\n",
    "    idf_row.append(idf)\n",
    "    idf_list = pd.DataFrame(idf_row, columns = fts['index'])\n",
    "    \n",
    "    # Extract term frequencies\n",
    "    tf = tfX.values\n",
    "    # Set up loop to multiply each article (row) by the idf per term (col)\n",
    "    tf_idf = []\n",
    "    r, c = tf.shape\n",
    "    for art in range(0,r):\n",
    "        tf_idf.append(tf[art]*idf)\n",
    "    tf_idf = pd.DataFrame(tf_idf, columns = fts['index'])\n",
    "    X = tf_idf\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(encodeType, **kwargs):\n",
    "    # 0 for Binary Encoding\n",
    "    # 1 for Term Frequency Encoding\n",
    "    # 2 for TF-IDF Encoding\n",
    "    # If you'd like to save as csv, use \"csv = True\"\n",
    "        \n",
    "    # Load up data\n",
    "    data = loadData()\n",
    "    \n",
    "    # Run corresponding encoding type and pass data\n",
    "    options = {0 : binEncoding,\n",
    "                1 : tfEncoding,\n",
    "                2 : tfidfEncoding,}\n",
    "    \n",
    "    X = options[encodeType](data)\n",
    "    \n",
    "    # Append Y column and article ids\n",
    "    Y = pd.DataFrame({'article_id':data['article_id'].values, 'market_moving':data['market_moving'].values})\n",
    "    XY = Y.join(X)\n",
    "    \n",
    "    # Save as csv file in CLASSIFICATION data folder =)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = options[encodeType].__name__ + '.csv'\n",
    "        thispath = Path().absolute()\n",
    "        #OUTPUT_DIR = os.path.join(thispath.parent.parent, \"Classification\", \"Data\", file_name)\n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "        pd.DataFrame.to_csv(XY, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(XY, path_or_buf=file_name)\n",
    "    \n",
    "    # Return Panda DataFrame\n",
    "    return XY\n",
    "    \n",
    "\n",
    "\n",
    "def main(): # Stuff to do when run from the command line    \n",
    "    encoding(0, csv = True)\n",
    "    pass  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Encoding\n"
     ]
    }
   ],
   "source": [
    "#testcell\n",
    "\n",
    "#X = encoding(1, csv=True)\n",
    "#X = encoding(2, csv=True)\n",
    "XY = encoding(0, csv=True)\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
